name: Scrape Indeed Costa Rica Jobs

on:
  workflow_dispatch:  # Manual trigger
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours (adjust as needed)

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: 🐍 Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: 📦 Install dependencies
        run: |
          pip install --upgrade pip
          pip install selenium webdriver-manager
      
      - name: 🌐 Set up Chrome
        uses: browser-actions/setup-chrome@v1
        with:
          chrome-version: stable
      
      - name: 🔍 Install ChromeDriver
        run: |
          pip install webdriver-manager
      
      - name: 🤖 Run Indeed scraper
        id: scrape
        continue-on-error: true  # Don't fail workflow if scraping fails
        run: |
          python indeed_ci_scraper.py
        env:
          CI: true
          GITHUB_ACTIONS: true
      
      - name: 📊 Check scrape results
        run: |
          if [ -f indeed_cr_jobs_*.csv ]; then
            echo "✅ CSV file created"
            ls -lh indeed_cr_jobs_*.csv
            echo "📝 Job count:"
            tail -n +2 indeed_cr_jobs_*.csv | wc -l
          else
            echo "⚠️ No CSV file found"
          fi
      
      - name: 📤 Upload scraped data
        if: always()  # Upload even if scraping failed
        uses: actions/upload-artifact@v4
        with:
          name: indeed-jobs-${{ github.run_number }}
          path: |
            indeed_cr_jobs_*.csv
            indeed_cr_jobs_*.json
            indeed_scraper.log
            *.png
            *.html
          retention-days: 30
      
      - name: 💾 Commit and push results
        if: success()  # Only commit if scraping succeeded
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          # Move files to data directory
          mkdir -p data
          mv indeed_cr_jobs_*.csv data/ 2>/dev/null || true
          mv indeed_cr_jobs_*.json data/ 2>/dev/null || true
          
          # Add and commit
          git add data/
          
          if git diff --staged --quiet; then
            echo "📭 No changes to commit"
          else
            git commit -m "🤖 Update jobs data - $(date +'%Y-%m-%d %H:%M:%S')"
            git push
            echo "✅ Changes pushed"
          fi
      
      - name: 📝 Summary
        if: always()
        run: |
          echo "## 📊 Scrape Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f indeed_cr_jobs_*.csv ]; then
            JOB_COUNT=$(tail -n +2 indeed_cr_jobs_*.csv | wc -l)
            echo "✅ **Jobs scraped:** $JOB_COUNT" >> $GITHUB_STEP_SUMMARY
          else
            echo "⚠️ **Status:** No jobs scraped (likely blocked by Cloudflare)" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### 🛠️ Recommendations:" >> $GITHUB_STEP_SUMMARY
            echo "- Consider using undetected-chromedriver" >> $GITHUB_STEP_SUMMARY
            echo "- Try running with Playwright" >> $GITHUB_STEP_SUMMARY
            echo "- Use Indeed's RSS feed instead" >> $GITHUB_STEP_SUMMARY
            echo "- Add proxy rotation" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "🕐 **Run time:** $(date)" >> $GITHUB_STEP_SUMMARY

  # Optional: Send notification on failure
  notify-failure:
    runs-on: ubuntu-latest
    needs: scrape
    if: failure()
    steps:
      - name: 📧 Send notification
        run: |
          echo "Scraping failed - check artifacts for debug files"
          # Add email/Slack notification here if needed

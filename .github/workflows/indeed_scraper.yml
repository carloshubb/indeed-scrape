name: Indeed Costa Rica Job Scraper

on:
  schedule:
    - cron: '0 8 * * *'
  
  workflow_dispatch:
    inputs:
      max_pages:
        description: 'Maximum pages to scrape'
        required: false
        default: '3'
      max_jobs:
        description: 'Maximum jobs (leave empty for all)'
        required: false
        default: '50'
      headless:
        description: 'Run in headless mode'
        required: false
        default: 'true'

jobs:
  scrape-jobs:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install system dependencies
      run: |
        echo "üì¶ Installing system dependencies..."
        sudo apt-get update
        sudo apt-get install -y wget unzip xvfb
        
        # Install Chrome
        wget -q https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
        sudo apt-get install -y ./google-chrome-stable_current_amd64.deb
        rm google-chrome-stable_current_amd64.deb
        
        # Verify Chrome installation
        google-chrome --version
        which google-chrome
    
    - name: Install Python dependencies
      run: |
        echo "üêç Installing Python packages..."
        python -m pip install --upgrade pip
        pip install selenium webdriver-manager
        pip list
    
    - name: Verify environment
      run: |
        echo "üîç Environment check:"
        echo "Python: $(python --version)"
        echo "Chrome: $(google-chrome --version)"
        echo "Working directory: $(pwd)"
        echo "Files: $(ls -la)"
        echo "Python path: $(which python)"
    
    - name: Run scraper
      env:
        MAX_PAGES: ${{ github.event.inputs.max_pages || '3' }}
        MAX_JOBS: ${{ github.event.inputs.max_jobs || '50' }}
        HEADLESS: ${{ github.event.inputs.headless || 'true' }}
        CI: 'true'
      run: |
        echo "üöÄ Starting scraper..."
        echo "Settings: MAX_PAGES=${MAX_PAGES}, MAX_JOBS=${MAX_JOBS}, HEADLESS=${HEADLESS}"
        
        # Run with xvfb for virtual display
        xvfb-run -a --server-args="-screen 0 1920x1080x24" python indeed_full_details_scraper.py
        
        echo "‚úÖ Scraper completed"
    
    - name: List generated files
      if: always()
      run: |
        echo "üìÅ Generated files:"
        ls -lh *.json *.csv 2>/dev/null || echo "No JSON/CSV files found"
        ls -lh debug_*.png debug_*.html 2>/dev/null || echo "No debug files"
    
    - name: Upload artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: scraper-results-${{ github.run_number }}
        path: |
          *.json
          *.csv
          debug_*.png
          debug_*.html
        retention-days: 30
        if-no-files-found: warn
    
    - name: Commit results to repository
      if: success()
      run: |
        echo "üíæ Committing results..."
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        
        # Create data directory
        mkdir -p data
        
        # Move results
        mv indeed_cr_jobs_*.json data/ 2>/dev/null || echo "No JSON to move"
        mv indeed_cr_jobs_*.csv data/ 2>/dev/null || echo "No CSV to move"
        
        # Check for changes
        if [ -n "$(git status --porcelain data/)" ]; then
          git add data/
          git commit -m "ü§ñ Update scraped jobs - $(date +'%Y-%m-%d %H:%M:%S UTC')"
          git push
          echo "‚úÖ Results committed and pushed"
        else
          echo "‚ÑπÔ∏è  No new data to commit"
        fi
      continue-on-error: true
    
    - name: Create job summary
      if: always()
      run: |
        echo "## üìä Scraper Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Run Details:**" >> $GITHUB_STEP_SUMMARY
        echo "- Date: $(date +'%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
        echo "- Max Pages: ${{ github.event.inputs.max_pages || '3' }}" >> $GITHUB_STEP_SUMMARY
        echo "- Max Jobs: ${{ github.event.inputs.max_jobs || '50' }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Count files
        JSON_COUNT=$(ls -1 *.json 2>/dev/null | wc -l)
        CSV_COUNT=$(ls -1 *.csv 2>/dev/null | wc -l)
        
        if [ $JSON_COUNT -gt 0 ] || [ $CSV_COUNT -gt 0 ]; then
          echo "**‚úÖ Success!**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- JSON files: $JSON_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "- CSV files: $CSV_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ $JSON_COUNT -gt 0 ]; then
            echo "### üìÑ Generated Files" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            ls -lh *.json *.csv 2>/dev/null >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          fi
        else
          echo "**‚ùå No files generated**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Check the logs for errors. Debug files may be available in artifacts." >> $GITHUB_STEP_SUMMARY
        fi
    
    - name: Notify on failure
      if: failure()
      run: |
        echo "‚ùå Scraper failed!"
        echo "Check the action logs and debug artifacts for details."
        exit 1

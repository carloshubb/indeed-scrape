name: Weekly Indeed Scraper

on:
  schedule:
    - cron: "0 0 * * 1"  # Every Monday at 00:00 UTC
  workflow_dispatch:      # Allow manual run

jobs:
  scrape-indeed:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      # 1Ô∏è‚É£ Checkout your repository
      - name: Checkout repository
        uses: actions/checkout@v4

      # 2Ô∏è‚É£ Set up Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      # 3Ô∏è‚É£ Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium undetected-chromedriver webdriver-manager

      # 4Ô∏è‚É£ Install Google Chrome & ChromeDriver
      - name: Install Google Chrome & ChromeDriver
        run: |
          sudo apt-get update
          sudo apt-get install -y wget unzip xvfb
          wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
          sudo dpkg -i google-chrome-stable_current_amd64.deb || sudo apt-get -fy install
          google-chrome --version

          # Match ChromeDriver version
          CHROME_VERSION=$(google-chrome --version | cut -d ' ' -f3 | cut -d '.' -f1)
          DRIVER_VERSION=$(curl -s "https://googlechromelabs.github.io/chrome-for-testing/LATEST_RELEASE_$CHROME_VERSION")
          wget -q "https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/${DRIVER_VERSION}/linux64/chromedriver-linux64.zip"
          unzip chromedriver-linux64.zip
          sudo mv chromedriver-linux64/chromedriver /usr/local/bin/
          sudo chmod +x /usr/local/bin/chromedriver
          chromedriver --version

      # 5Ô∏è‚É£ Run Indeed scraper (stealth mode)
      - name: Run Indeed scraper
        env:
          PYTHONUNBUFFERED: 1
        run: |
          python - <<'EOF'
          import time, csv, json
          from datetime import datetime
          from selenium.webdriver.chrome.options import Options
          from selenium.webdriver.common.by import By
          from selenium import webdriver

          print("üöÄ Running Indeed Scraper (CI Headless Stealth Mode)")

          # üß† Headless + stealth Chrome config
          options = Options()
          options.add_argument("--headless=new")
          options.add_argument("--no-sandbox")
          options.add_argument("--disable-dev-shm-usage")
          options.add_argument("--disable-blink-features=AutomationControlled")
          options.add_argument("--window-size=1920,1080")
          options.add_argument("--disable-gpu")
          options.add_argument("--lang=en-US,en")
          options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                                "AppleWebKit/537.36 (KHTML, like Gecko) "
                                "Chrome/120.0.0.0 Safari/537.36")

          driver = webdriver.Chrome(options=options)
          url = "https://cr.indeed.com/jobs?q=&l=costa+rica"
          print(f"üîç Navigating to: {url}")
          driver.get(url)
          time.sleep(5)

          job_cards = driver.find_elements(By.CSS_SELECTOR, "div.job_seen_beacon")
          print(f"üìä Found {len(job_cards)} job cards")

          if not job_cards:
              print("‚ö†Ô∏è No job listings visible ‚Äî possibly CAPTCHA or region restriction.")
              driver.save_screenshot("indeed_debug.png")
              driver.quit()
              exit(1)

          jobs = []
          for card in job_cards[:10]:
              try:
                  title = card.find_element(By.CSS_SELECTOR, "h2 span").text.strip()
                  company = card.find_element(By.CSS_SELECTOR, "span[data-testid='company-name']").text.strip()
                  location = card.find_element(By.CSS_SELECTOR, "div[data-testid='text-location']").text.strip()
                  jobs.append({"title": title, "company": company, "location": location})
              except Exception:
                  pass

          timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
          json_file = f"indeed_jobs_{timestamp}.json"
          csv_file = f"indeed_jobs_{timestamp}.csv"

          with open(json_file, "w", encoding="utf-8") as f:
              json.dump(jobs, f, indent=2, ensure_ascii=False)

          with open(csv_file, "w", encoding="utf-8", newline="") as f:
              writer = csv.DictWriter(f, fieldnames=["title", "company", "location"])
              writer.writeheader()
              writer.writerows(jobs)

          driver.quit()
          print(f"‚úÖ Scraped {len(jobs)} jobs ‚Üí Saved to {csv_file}")
          EOF

      # 6Ô∏è‚É£ Upload scraped data and debug files
      - name: Upload scraped data
        uses: actions/upload-artifact@v4
        with:
          name: indeed-scraped-data
          path: |
            *.csv
            *.json
            indeed_debug.png